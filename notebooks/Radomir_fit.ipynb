{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from scipy.special import gamma\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "import pickle\n",
    "import string\n",
    "digs = string.digits + string.ascii_letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RungeKutta:\n",
    "    \"\"\"\n",
    "    Implementation of 4th order Runge-Kutta integration\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, beta, rho, sigma, dt):\n",
    "        self.beta = beta\n",
    "        self.rho = rho\n",
    "        self.sigma = sigma\n",
    "        self.dt = dt\n",
    "\n",
    "    def deriviation_step(self, initial_state, derivative, dt):\n",
    "        \"\"\"\n",
    "        Compute one evaluation step\n",
    "        \"\"\"\n",
    "\n",
    "        # evaluation of state\n",
    "        state = {}\n",
    "\n",
    "        if not derivative:\n",
    "            state[\"x\"] = initial_state[\"x\"]\n",
    "            state[\"y\"] = initial_state[\"y\"]\n",
    "            state[\"z\"] = initial_state[\"z\"]\n",
    "        else:\n",
    "            state[\"x\"] = initial_state[\"x\"] + derivative[\"dx\"] * dt\n",
    "            state[\"y\"] = initial_state[\"y\"] + derivative[\"dy\"] * dt\n",
    "            state[\"z\"] = initial_state[\"z\"] + derivative[\"dz\"] * dt\n",
    "\n",
    "        # evaluation of derivative\n",
    "        derivative_next_step = {}\n",
    "\n",
    "        derivative_next_step[\"dx\"] = self.sigma * (state[\"y\"] - state[\"x\"])\n",
    "        derivative_next_step[\"dy\"] = self.rho * state[\"x\"] - state[\"y\"] - state[\"x\"] * state[\"z\"]\n",
    "        derivative_next_step[\"dz\"] = state[\"x\"] * state[\"y\"] - self.beta * state[\"z\"]\n",
    "\n",
    "        return derivative_next_step\n",
    "\n",
    "    def _integration_step(self, state, dt):\n",
    "        \"\"\"\n",
    "        Runge-Kutta integration of the 4th order at a time `t` with a state `state`\n",
    "        with the step `dt`\n",
    "        \"\"\"\n",
    "        # Prepare 1,2,3,4 - order derivatives for the final \"best\" derivative,\n",
    "        # gained as 4 first elements of the Taylor's approximation\n",
    "\n",
    "        # Random initialization of defivatives(probably will have to moove)\n",
    "        derivative = dict({\"dx\": np.random.normal(),\n",
    "                           \"dy\": np.random.normal(),\n",
    "                           \"dz\": np.random.normal()})\n",
    "        rk1 = self.deriviation_step(initial_state=state,\n",
    "                                    derivative=None,\n",
    "                                    dt=dt * 0)\n",
    "\n",
    "        rk2 = self.deriviation_step(initial_state=state,\n",
    "                                    derivative=rk1,\n",
    "                                    dt=dt * 0.5\n",
    "                                    )\n",
    "\n",
    "        rk3 = self.deriviation_step(initial_state=state,\n",
    "                                    derivative=rk2,\n",
    "                                    dt=dt * 0.5)\n",
    "\n",
    "        rk4 = self.deriviation_step(initial_state=state,\n",
    "                                    derivative=rk3,\n",
    "                                    dt=dt)\n",
    "\n",
    "        # When all derivatives are ready, it's time to construct Rung-Kutta derivative\n",
    "        # !!!! DOUBLE CHECK THE TAYLOR'S APPROXIMATIONS !!!!\n",
    "        dxdt = (1 / 6) * (rk1[\"dx\"] + 2 * rk2[\"dx\"] + 2 * rk3[\"dx\"] + rk4[\"dx\"])\n",
    "        dydt = (1 / 6) * (rk1[\"dy\"] + 2 * rk2[\"dy\"] + 2 * rk3[\"dy\"] + rk4[\"dy\"])\n",
    "        dzdt = (1 / 6) * (rk1[\"dz\"] + 2 * rk2[\"dz\"] + 2 * rk3[\"dz\"] + rk4[\"dz\"])\n",
    "\n",
    "        state[\"x\"] = state[\"x\"] + dxdt * dt\n",
    "        state[\"y\"] = state[\"y\"] + dydt * dt\n",
    "        state[\"z\"] = state[\"z\"] + dzdt * dt\n",
    "        return state\n",
    "\n",
    "    def get_series(self, n_iterations, initial_state=None):\n",
    "        \"\"\"\n",
    "        Does a series of integration steps to get a series\n",
    "        :return: numpy array of series\n",
    "        \"\"\"\n",
    "        if not initial_state:\n",
    "            initial_state = dict({\"x\": 0.62225717,\n",
    "                                  \"y\": -0.08232857,\n",
    "                                  \"z\": 30.60845379})\n",
    "\n",
    "        ode_solutions = []\n",
    "        for iteration in range(0, n_iterations):\n",
    "            state_t = self._integration_step(initial_state, dt=self.dt)\n",
    "            ode_solutions.append(list(state_t.values()))\n",
    "        result = np.array(ode_solutions)\n",
    "        return result[:, 0]\n",
    "\n",
    "\n",
    "def reconstruct_lorenz(ts: np.ndarray, template: np.ndarray):\n",
    "    ts_list = [ts[:-np.sum(template)].reshape(-1, 1)]\n",
    "\n",
    "    for offset in template.cumsum()[:-1]:\n",
    "        offset_ts = ts[offset:-(template.sum() - offset)].reshape(-1, 1)\n",
    "        ts_list.append(offset_ts)\n",
    "    ts_list.append(ts[np.sum(template):].reshape(-1, 1))\n",
    "    reconstructed_ts = np.concatenate(ts_list, axis=1)\n",
    "    return reconstructed_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int2base(x, base):\n",
    "    if x < 0:\n",
    "        sign = -1\n",
    "    elif x == 0:\n",
    "        return digs[0]\n",
    "    else:\n",
    "        sign = 1\n",
    "\n",
    "    x *= sign\n",
    "    digits = []\n",
    "\n",
    "    while x:\n",
    "        digits.append(digs[int(x % base)])\n",
    "        x = int(x / base)\n",
    "\n",
    "    if sign < 0:\n",
    "        digits.append('-')\n",
    "\n",
    "    digits.reverse()\n",
    "\n",
    "    return ''.join(digits)\n",
    "\n",
    "class TemplateManager:\n",
    "\n",
    "    def __init__(self, template_size, max_template_distance, min_template_distance):\n",
    "        \"\"\"\n",
    "\n",
    "        :param max_template_distance: Max number of points between two nearest points in a template\n",
    "        :param min_template_distance: Min number of points between two nearest points in a template\n",
    "        :param template_size: Number of points in a template <-> sizeof the z-vector\n",
    "        \"\"\"\n",
    "        self.template_size = template_size\n",
    "        self.max_template_distance = max_template_distance\n",
    "        self.min_template_distance = min_template_distance\n",
    "        self.current_template = 0\n",
    "        self.current_template_name = (\"0_\" * self.template_size)[:-1]\n",
    "\n",
    "    def set_current_template(self, new_current_template):\n",
    "        self.current_template = new_current_template\n",
    "\n",
    "    def get_current_template_name(self):\n",
    "        return self.current_template_name\n",
    "\n",
    "    def _template_from_str_to_int(self, template):\n",
    "        \"\"\"\n",
    "        String representation of template to integer representation of templete\n",
    "        :Str, List[str] template: List with strings, which represent distance between point.\n",
    "                        e.g. [\"0\", \"a\", \"9\", \"b\"] will result in [0, 10, 9, 11]\n",
    "        :return: List[int] template\n",
    "        \"\"\"\n",
    "        if type(template) is list:\n",
    "            template = [digs.find(element) for element in template]\n",
    "        elif type(template) is str:\n",
    "            template = template.rjust(self.template_size, \"0\")\n",
    "            template = list(template)\n",
    "            template = [digs.find(element) for element in template]\n",
    "        else:\n",
    "            raise Exception(\"-> Template of wrong type %s\" % type(template))\n",
    "        return template\n",
    "\n",
    "    def _template_from_int_to_str(self, template):\n",
    "        \"\"\"\n",
    "        Converts the int or list of int's to a list of strings\n",
    "        :param template: int / list[int]\n",
    "        :return: list[str]\n",
    "        \"\"\"\n",
    "        if type(template) is int:\n",
    "            template = int2base(x=template, base=self.max_template_distance + 1)\n",
    "            template = template.rjust(self.template_size, \"0\")\n",
    "            template = list(template)\n",
    "        elif type(template) is list:\n",
    "            template = [int2base(element, base=self.max_template_distance + 1) for element in template]\n",
    "        self.current_template_name = \"_\".join(template)\n",
    "        return template\n",
    "\n",
    "    def _check_templates_validity(self, template):\n",
    "        \"\"\"\n",
    "        Check if templates satisfies the borders for the template distances.\n",
    "        :List[int] template: template with integers and template distances\n",
    "        :return: True/False\n",
    "        \"\"\"\n",
    "\n",
    "        def check_element(x):\n",
    "            return (x >= self.min_template_distance) & (x <= self.max_template_distance)\n",
    "\n",
    "        checked_template = list(map(check_element, template))\n",
    "        if all(checked_template):\n",
    "            return True\n",
    "        else:\n",
    "            # print(\"Element doesn't fit diapason %i-%i\" % (self.min_template_distance, self.max_template_distance))\n",
    "            return False\n",
    "\n",
    "    def next_planned_template(self, method=\"concurrent\", step=5):\n",
    "        \"\"\"\n",
    "\n",
    "        :strr method: object\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        assert (type(step) is int) & (step >= 1), \"Template step is not integer or not big enough \"\n",
    "        # TODO: Repeat while the template satisfies the conditions\n",
    "        next_template = self._template_from_int_to_str(self.current_template)\n",
    "        next_template = self._template_from_str_to_int(next_template)\n",
    "        # Skip those templates, which does not satisfies the specification.\n",
    "        while not self._check_templates_validity(template=next_template):\n",
    "\n",
    "            if method == \"random\":\n",
    "                next_template = np.random.random_integers(low=self.min_template_distance,\n",
    "                                                          high=self.max_template_distance,\n",
    "                                                          size=self.template_size - 1)\n",
    "            elif method == \"concurrent\":\n",
    "                self.current_template = self.current_template + step\n",
    "                if self.current_template > (self.max_template_distance + 1) ** self.template_size:\n",
    "                    print(\"-> Run out of templates\")\n",
    "                    return False\n",
    "                next_template = self._template_from_int_to_str(self.current_template)\n",
    "                next_template = self._template_from_str_to_int(next_template)\n",
    "                # print(\"--> \", next_template, self._check_templates_validity(template=next_template))\n",
    "            else:\n",
    "                raise Exception(\"-> Unspecified method to generate templates. Must be \\\"random\\\" or \\\"concurrent\\\"\")\n",
    "        self.current_template = self.current_template + step\n",
    "        return next_template\n",
    "\n",
    "    def next_planned_significance(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return 0.1\n",
    "\n",
    "    def next_planned_neighbors(self):\n",
    "        \"\"\"\n",
    "        tm = TemplateManager(5, 10, 0)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wishart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_sorted_vertexes_matrix_r(X, wishart_neighbors):\n",
    "    kdt = KDTree(X, metric='euclidean')\n",
    "    distances, neighbors = kdt.query(X, k=wishart_neighbors + 1)\n",
    "    neighbors = neighbors[:, 1:]\n",
    "    distances = distances[:, -1]\n",
    "    indexes = np.argsort(distances)\n",
    "    return neighbors, distances, indexes\n",
    "\n",
    "\n",
    "def find_connected_clusters(graph_vertexes, vertex_neighbors, index):\n",
    "    neighbors_clusters = graph_vertexes[vertex_neighbors[index]]\n",
    "    unique_clusters = np.unique(neighbors_clusters).astype(int)\n",
    "    unique_clusters = unique_clusters[unique_clusters != -1]\n",
    "    return unique_clusters\n",
    "\n",
    "\n",
    "class WishartClassifier:\n",
    "    def __init__(self, wishart_neighbors, significance_level):\n",
    "        self.wishart_neighbors = wishart_neighbors  # Number of neighbors\n",
    "        self.significance_level = significance_level  # Significance level\n",
    "\n",
    "    def fit(self, X):\n",
    "        neighbors, distances, indexes = construct_sorted_vertexes_matrix_r(X, self.wishart_neighbors)\n",
    "\n",
    "        size, dim = X.shape\n",
    "        self.object_labels = np.zeros(size, dtype=int) - 1\n",
    "        self.clusters = np.array([(1., 1., 0)])\n",
    "        self.clusters_to_objects = defaultdict(list)\n",
    "\n",
    "        for index in indexes:\n",
    "\n",
    "            unique_clusters = find_connected_clusters(self.object_labels, neighbors, index)\n",
    "\n",
    "            if len(unique_clusters) == 0:\n",
    "                self._create_new_cluster(index, distances[index])\n",
    "            else:\n",
    "                max_cluster = unique_clusters[-1]\n",
    "                min_cluster = unique_clusters[0]\n",
    "                if max_cluster == min_cluster:\n",
    "                    if self.clusters[max_cluster][-1] < 0.5:\n",
    "                        self._add_elem_to_exist_cluster(index, distances[index], max_cluster)\n",
    "                    else:\n",
    "                        self._add_elem_to_noise(index)\n",
    "                else:\n",
    "                    my_clusters = self.clusters[unique_clusters]\n",
    "                    flags = my_clusters[:, -1]\n",
    "                    if np.min(flags) > 0.5:\n",
    "                        self._add_elem_to_noise(index)\n",
    "                    else:\n",
    "                        significan = np.power(my_clusters[:, 0], -dim) - np.power(my_clusters[:, 1], -dim)\n",
    "                        significan *= self.wishart_neighbors\n",
    "                        significan /= size\n",
    "                        significan /= np.power(np.pi, dim / 2)\n",
    "                        significan *= gamma(dim / 2 + 1)\n",
    "                        significan_index = significan >= self.significance_level\n",
    "\n",
    "                        significan_clusters = unique_clusters[significan_index]\n",
    "                        not_significan_clusters = unique_clusters[~significan_index]\n",
    "                        significan_clusters_count = len(significan_clusters)\n",
    "                        if significan_clusters_count > 1 or min_cluster == 0:\n",
    "                            self._add_elem_to_noise(index)\n",
    "                            self.clusters[significan_clusters, -1] = 1\n",
    "                            for not_sig_cluster in not_significan_clusters:\n",
    "                                if not_sig_cluster == 0:\n",
    "                                    continue\n",
    "\n",
    "                                for bad_index in self.clusters_to_objects[not_sig_cluster]:\n",
    "                                    self._add_elem_to_noise(bad_index)\n",
    "                                self.clusters_to_objects[not_sig_cluster].clear()\n",
    "                        else:\n",
    "                            for cur_cluster in unique_clusters:\n",
    "                                if cur_cluster == min_cluster:\n",
    "                                    continue\n",
    "\n",
    "                                for bad_index in self.clusters_to_objects[cur_cluster]:\n",
    "                                    self._add_elem_to_exist_cluster(bad_index, distances[bad_index], min_cluster)\n",
    "                                self.clusters_to_objects[cur_cluster].clear()\n",
    "                            self._add_elem_to_exist_cluster(index, distances[index], min_cluster)\n",
    "\n",
    "        return self.clear()\n",
    "\n",
    "    def clear(self):\n",
    "        unique = np.unique(self.object_labels)\n",
    "        index = np.argsort(unique)\n",
    "        if unique[0] != 0:\n",
    "            index += 1\n",
    "        true_cluster = {unq: index for unq, index in zip(unique, index)}\n",
    "        result = np.zeros(len(self.object_labels), dtype=int)\n",
    "        for index, unq in enumerate(self.object_labels):\n",
    "            result[index] = true_cluster[unq]\n",
    "        return result\n",
    "\n",
    "    def _add_elem_to_noise(self, index):\n",
    "        self.object_labels[index] = 0\n",
    "        self.clusters_to_objects[0].append(index)\n",
    "\n",
    "    def _create_new_cluster(self, index, dist):\n",
    "        self.object_labels[index] = len(self.clusters)\n",
    "        self.clusters_to_objects[len(self.clusters)].append(index)\n",
    "        self.clusters = np.append(self.clusters, [(dist, dist, 0)], axis=0)\n",
    "\n",
    "    def _add_elem_to_exist_cluster(self, index, dist, cluster_label):\n",
    "        self.object_labels[index] = cluster_label\n",
    "        self.clusters_to_objects[cluster_label].append(index)\n",
    "        self.clusters[cluster_label][0] = min(self.clusters[cluster_label][0], dist)\n",
    "        self.clusters[cluster_label][1] = max(self.clusters[cluster_label][1], dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_template_dict(template_name, clusters, data_lorenz):\n",
    "    unique_clusters = np.unique(clusters)\n",
    "    unique_clusters = np.delete(unique_clusters, 0)\n",
    "    cluster_centers = []\n",
    "    cluster_sizes = []\n",
    "    for cluster in unique_clusters:\n",
    "        mask = clusters == cluster\n",
    "        zvectors = data_lorenz[mask]\n",
    "        cluster_center = zvectors.mean(0)\n",
    "        cluster_centers.append(cluster_center)\n",
    "        cluster_sizes.append(mask.sum())\n",
    "    \n",
    "    cluster_sizes = np.array(cluster_sizes)\n",
    "    cluster_centers = np.array(cluster_centers)\n",
    "    zvector_base = cluster_centers[:, :-1]\n",
    "    predicted_values = cluster_centers[:, -1]\n",
    "    \n",
    "    kdtree = cKDTree(zvector_base)\n",
    "    \n",
    "    template_dict = {\"template_name\": template_name,\n",
    "                     \"cluster_sizes\": cluster_sizes,\n",
    "                     \"kdtree\": kdtree,\n",
    "                     \"predicted_values\": predicted_values}\n",
    "    return template_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rk = RungeKutta(beta=8 / 3, rho=28, sigma=10, dt=0.1)\n",
    "lorenz_train = rk.get_series(n_iterations=int(3e5))\n",
    "lorenz_train = lorenz_train / abs(lorenz_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TemplateManager(template_size=4, max_template_distance=10, min_template_distance=1)\n",
    "tm.current_template = 3000\n",
    "STEP = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(300):\n",
    "    \n",
    "    template = tm.next_planned_template(step=10)\n",
    "    template_name = tm.get_current_template_name()\n",
    "    \n",
    "    reconstructed_train_lorenz = reconstruct_lorenz(lorenz_train, np.array(template))\n",
    "    \n",
    "    ws = WishartClassifier(11, 0.1)\n",
    "    clusters = ws.fit(reconstructed_train_lorenz)\n",
    "    \n",
    "    template_dict = construct_template_dict(template_name, clusters, reconstructed_train_lorenz)\n",
    "    \n",
    "    with open((\"models/\" + template_name + \".pkl\"), \"wb\") as f:\n",
    "        pickle.dump(template_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
